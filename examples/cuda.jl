using AffineScaler: rescale_one_zero
using CUDA
# using Distributions: LogUniform
using GeneralizedSP2
using GeneralizedSP2: DOUBLE, SINGLE, MIXED
using LinearAlgebra
# using Plots
# using ToyHamiltonians
using NPZ

PLOT_DEFAULTS = Dict(
    :size => (400, 300),
    :dpi => 400,
    :framestyle => :box,
    :linewidth => 1,
    :markersize => 1,
    :markerstrokewidth => 0,
    :minorticks => 5,
    :titlefontsize => 9,
    :plot_titlefontsize => 9,
    :guidefontsize => 9,
    :tickfontsize => 7,
    :legendfontsize => 7,
    :left_margin => (0, :mm),
    :grid => nothing,
    :legend_foreground_color => nothing,
    :legend_background_color => nothing,
    :legend_position => :bottomleft,
    :background_color_inside => nothing,
    :color_palette => :tab10,
)

function direct_sum(matrices::Matrix...)
    # Calculate the total size of the resulting matrix
    total_rows = sum(size(mat, 1) for mat in matrices)
    total_cols = sum(size(mat, 2) for mat in matrices)
    # Initialize a zero matrix of the required size
    result = zeros(eltype(matrices[1]), total_rows, total_cols)
    # Place each matrix in its corresponding block
    row_offset = 0
    col_offset = 0
    for mat in matrices
        rows, cols = size(mat)
        result[(row_offset + 1):(row_offset + rows), (col_offset + 1):(col_offset + cols)] =
            mat
        row_offset += rows
        col_offset += cols
    end
    return result
end

Œ≤ = 1.25  # Physical
Œº = 11.5  # Physical
# sys_size = 1024
# dist = LogUniform(1, 20)
# Œõ = rand(EigvalsSampler(dist), sys_size)
# V = rand(EigvecsSampler(dist), sys_size, sys_size)
# set_isapprox_rtol(1e-13)
# H = CuMatrix(Hamiltonian(Eigen(Œõ, V)))
H = npzread("H.npy")
H = direct_sum(H, H, H, H)
ùõå = eigvals(H)
Œµ‚Çò·µ¢‚Çô, Œµ‚Çò‚Çê‚Çì = floor(minimum(ùõå)), ceil(maximum(ùõå))
Œ≤‚Ä≤ = rescale_beta((Œµ‚Çò·µ¢‚Çô, Œµ‚Çò‚Çê‚Çì))(Œ≤)
Œº‚Ä≤ = rescale_mu((Œµ‚Çò·µ¢‚Çô, Œµ‚Çò‚Çê‚Çì))(Œº)
H_scaled = rescale_one_zero(Œµ‚Çò·µ¢‚Çô, Œµ‚Çò‚Çê‚Çì)(H)

# lower_bound, upper_bound = 0, 1
# ùê±‚Ä≤ = chebyshevnodes_1st(1000, (lower_bound, upper_bound))
# fitted = fit_fermi_dirac(ùê±‚Ä≤, Œº‚Ä≤, Œ≤‚Ä≤, init_model(Œº‚Ä≤, 18); max_iter=10000)
# M = fitted.model
M = loadmodel("18_1qw.npy")

N = 4096

function exactcpu(N)
    X = H_scaled[1:N, 1:N]
    return CUDA.@profile fermi_dirac(X, Œº‚Ä≤, Œ≤‚Ä≤)
end
# cpu_exact = exactcpu(N)
# exact_N = tr(cpu_exact)
# exact_fd = diag(inv(V‚Ä≤) * cpu_exact * V‚Ä≤)

function modelcpu(N)
    X = H_scaled[1:N, 1:N]
    return CUDA.@profile fermi_dirac(M)(X)
end
# cpu_model = modelcpu(N)
# cpu_N = tr(cpu_model)
# cpu_fd = diag(inv(V) * cpu_model * V)

function modelcu(N; preheat=3)  # Julia model
    X = CuMatrix(H_scaled[1:N, 1:N])
    DM = zero(X)
    for _ in 1:preheat
        M(DM, X)  # Preheating GPU
    end
    CUDA.@profile M(DM, X)  # Only profile the last run
    return DM
end
function modelgpu(N, precision::Precision; preheat=3)  # CUDA
    X = CuMatrix(H[1:N, 1:N])
    DM = zero(X)
    for _ in 1:preheat
        M(DM, X, precision, (Œµ‚Çò·µ¢‚Çô, Œµ‚Çò‚Çê‚Çì))  # Preheating GPU
    end
    CUDA.@profile M(DM, X, precision, (Œµ‚Çò·µ¢‚Çô, Œµ‚Çò‚Çê‚Çì))
    return DM
end

function exactgpu(N, Œº, Œ≤; preheat=3)  # Julia
    X = CuMatrix(H[1:N, 1:N])
    DM = zero(X)
    for _ in 1:preheat
        fermi_dirac!(DM, X, Œº, Œ≤)  # Preheating GPU
    end
    CUDA.@profile fermi_dirac!(DM, X, Œº, Œ≤)
    return DM
end

function exactcuda(N, Œº, Œ≤; preheat=3)  # CUDA
    X = CuMatrix(H[1:N, 1:N])
    DM = zero(X)
    for _ in 1:preheat
        compute_exact_fermi_dirac!(DM, X, Œº, Œ≤)  # Preheating GPU
    end
    CUDA.@profile compute_exact_fermi_dirac!(DM, X, Œº, Œ≤)
    return DM
end

# layout = (2, 1)
# plot(; layout=layout, PLOT_DEFAULTS..., size=(1600 / 3, 800))
# scatter!(ùõå, fd_benchmark; subplot=1, label="target Fermi‚ÄìDirac", PLOT_DEFAULTS...)
# scatter!(ùõå, fd_cpu; subplot=1, label="MLSP2 model", PLOT_DEFAULTS...)
# scatter!(ùõå, fd_gpu; subplot=1, label="MLSP2 model CUDA", PLOT_DEFAULTS...)
# xlabel!("eigenvalues of H"; subplot=1)
# ylabel!("Fermi‚ÄìDirac distribution"; subplot=1)

# hline!(
#     [zero(eltype(fd_benchmark))];
#     subplot=2,
#     seriescolor=:black,
#     primary=false,
#     PLOT_DEFAULTS...,
# )
# scatter!(ùõå, fd_benchmark - fd_cpu; subplot=2, label="MLSP2 model", PLOT_DEFAULTS...)
# scatter!(ùõå, fd_benchmark - fd_gpu; subplot=2, label="MLSP2 model CUDA", PLOT_DEFAULTS...)
# xlabel!("eigenvalues of H"; subplot=2)
# ylabel!("Fermi‚ÄìDirac distribution difference"; subplot=2)
